import os
import streamlit as st
from PyPDF2 import PdfReader

# âœ… v0.2+ ê¶Œì¥ ì„í¬íŠ¸
from langchain.text_splitter import CharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain


def get_pdf_text(pdf_docs):
    text = ""
    for pdf in pdf_docs or []:
        reader = PdfReader(pdf)
        for page in reader.pages:
            # ì¼ë¶€ PDFëŠ” extract_text()ê°€ Noneì„ ë°˜í™˜í•  ìˆ˜ ìˆìŒ â†’ ë°©ì–´ ì½”ë“œ
            page_text = page.extract_text() or ""
            text += page_text + "\n"
    return text


def get_text_chunks(text: str):
    splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len,
    )
    return splitter.split_text(text)


def get_vectorstore(text_chunks, openai_api_key: str):
    embeddings = OpenAIEmbeddings(
        api_key=openai_api_key,
        model="text-embedding-3-small",
    )
    return FAISS.from_texts(texts=text_chunks, embedding=embeddings)


def get_conversation_chain(vectorstore, openai_api_key: str):
    llm = ChatOpenAI(
        api_key=openai_api_key,
        model="gpt-4o-mini",
        temperature=0.2,
    )
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True
    )
    chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vectorstore.as_retriever(),
        memory=memory,
    )
    return chain


def handle_userinput(user_question: str):
    if not st.session_state.conversation:
        st.warning("ë¨¼ì € PDFë¥¼ ì—…ë¡œë“œí•˜ê³  â€˜Processâ€™ë¥¼ ëˆŒëŸ¬ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        return

    response = st.session_state.conversation({"question": user_question})
    st.session_state.chat_history = response.get("chat_history", [])

    for i, message in enumerate(st.session_state.chat_history):
        role = "user" if i % 2 == 0 else "ai"
        with st.chat_message(role):
            st.write(message.content)


def main():
    st.set_page_config(page_title="PDF Q&A", page_icon="ğŸ“š")
    st.header("PDF Q&A ğŸ“š")

    # ğŸ” API í‚¤ ì…ë ¥(Secrets â†’ í™˜ê²½ë³€ìˆ˜ ìˆœ â†’ ì…ë ¥ì°½)
    sidebar_key = st.sidebar.text_input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
    env_key = os.getenv("OPENAI_API_KEY")
    secrets_key = st.secrets.get("OPENAI_API_KEY") if hasattr(st, "secrets") else None
    openai_api_key = sidebar_key or secrets_key or env_key

    if not openai_api_key:
        st.info("ê³„ì†í•˜ë ¤ë©´ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ Secrets/í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •í•˜ì„¸ìš”.")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    st.session_state.setdefault("conversation", None)
    st.session_state.setdefault("chat_history", [])

    # ì§ˆë¬¸ ì…ë ¥
    user_question = st.text_input("PDFì— ì§ˆë¬¸í•˜ê¸°:")
    if user_question:
        handle_userinput(user_question)

    # ì‚¬ì´ë“œë°”: PDF ì—…ë¡œë“œ & ì²˜ë¦¬
    with st.sidebar:
        st.subheader("PDF íŒŒì¼")
        pdf_docs = st.file_uploader(
            "PDFë¥¼ ì—…ë¡œë“œí•˜ê³  â€˜Processâ€™ë¥¼ ëˆ„ë¥´ì„¸ìš”",
            type=["pdf"],
            accept_multiple_files=True
        )
        if st.button("Process"):
            if not openai_api_key:
                st.warning("ë¨¼ì € OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
                st.stop()
            if not pdf_docs:
                st.warning("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
                st.stop()

            with st.spinner("Processing..."):
                # 1) PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
                raw_text = get_pdf_text(pdf_docs)
                if not raw_text.strip():
                    st.error("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìŠ¤ìº”ë³¸/ì´ë¯¸ì§€ PDFì¼ ìˆ˜ ìˆì–´ìš”.")
                    st.stop()

                # 2) ì²­í¬ ë¶„í• 
                chunks = get_text_chunks(raw_text)

                # 3) ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
                vectorstore = get_vectorstore(chunks, openai_api_key)

                # 4) ëŒ€í™” ì²´ì¸ êµ¬ì„±
                st.session_state.conversation = get_conversation_chain(vectorstore, openai_api_key)

                st.success("ì¤€ë¹„ ì™„ë£Œ! ì´ì œ ì§ˆë¬¸ì„ ì…ë ¥í•´ë³´ì„¸ìš”.")


if __name__ == "__main__":
    main()
